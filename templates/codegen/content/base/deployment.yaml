apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:  
    tad.gitops.set/image: ".spec.template.spec.containers[0].image"
    tad.gitops.get/image: ".spec.template.spec.containers[0].image"
    tad.gitops.set/replicas: ".spec.replicas"
    tad.gitops.get/replicas: ".spec.replicas" 
  labels: 
    app.kubernetes.io/instance: ${{ values.name }}
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/name:  ${{ values.name }}
    app.kubernetes.io/part-of: ${{ values.name }}  
  name: ${{ values.name }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance:  ${{ values.name }} 
  template:
    metadata: 
      labels:
        app.kubernetes.io/instance:  ${{ values.name }}
    spec:
      initContainers:
      - name: model-file
        image: quay.io/yangcao/mistral-7b-code-16k-qlora:latest
        command: [sh,-c, "/usr/bin/install /model/model.file /shared/"]
        volumeMounts:
        - name: model-file
          mountPath: /shared
      containers:
      - env:
        - name: MODEL_ENDPOINT
          value: http://0.0.0.0:8001
        image: quay.io/ai-lab/codegen:latest
        name: codegen-inference
        ports:
        - containerPort: 8501
          hostPort: 8501
        securityContext:
          runAsNonRoot: true
      - env:
        - name: HOST
          value: "0.0.0.0"
        - name: PORT
          value: "8001"
        - name: MODEL_PATH
          value: /model/model.file
        image: quay.io/ai-lab/llamacpp_python:latest
        name: codegen-model-service
        ports:
        - containerPort: 8001
          hostPort: 8001
        securityContext:
          runAsNonRoot: true
        volumeMounts:
        - name: model-file
          mountPath: /model
      volumes:
      - name: model-file
        emptyDir: {}



# apiVersion: v1
# kind: Pod
# metadata:
#   labels:
#     app: codegen
#   name: codegen
# spec:
#   initContainers:
#   - name: model-file
#     image: quay.io/yangcao/mistral-7b-code-16k-qlora:latest
#     command: [sh,-c, "/usr/bin/install /model/model.file /shared/"]
#     volumeMounts:
#     - name: model-file
#       mountPath: /shared
#   containers:
#   - env:
#     - name: MODEL_ENDPOINT
#       value: http://0.0.0.0:8001
#     image: quay.io/ai-lab/codegen:latest
#     name: codegen-inference
#     ports:
#     - containerPort: 8501
#       hostPort: 8501
#     securityContext:
#       runAsNonRoot: true
#   - env:
#     - name: HOST
#       value: "0.0.0.0"
#     - name: PORT
#       value: "8001"
#     - name: MODEL_PATH
#       value: /model/model.file
#     image: quay.io/ai-lab/llamacpp_python:latest
#     name: codegen-model-service
#     ports:
#     - containerPort: 8001
#       hostPort: 8001
#     securityContext:
#       runAsNonRoot: true
#     volumeMounts:
#     - name: model-file
#       mountPath: /model
#   volumes:
#   - name: model-file
#     emptyDir: {}
